# FORESIGHT â€” Expected Test Results with NASA CMAPSS Data

## ğŸ“Š Dataset Overview

**NASA CMAPSS** (Commercial Modular Aero-Propulsion System Simulation)
- **Source**: NASA Prognostics Center of Excellence
- **File**: `train_FD001.txt`
- **Engines**: 100
- **Total Records**: 20,631 sensor readings
- **Sensors**: 21 per engine (temperature, pressure, RPM, etc.)
- **Purpose**: Predict remaining useful life (RUL) of turbofan engines

## ğŸ”„ Test Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           TEST PIPELINE STEPS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  STEP 1: START SERVICES                                                     â”‚
â”‚  â”œâ”€â”€ Docker containers: zookeeper, kafka, postgres, mongodb, minio         â”‚
â”‚  â””â”€â”€ Status: âœ… All services healthy                                        â”‚
â”‚                                                                             â”‚
â”‚  STEP 2: CONVERT CMAPSS                                                     â”‚
â”‚  â”œâ”€â”€ Input: 20,631 raw records                                              â”‚
â”‚  â”œâ”€â”€ Output: ~80,000 sensor readings (4 sensor types per engine)           â”‚
â”‚  â””â”€â”€ File: data/processed/engine_data.csv                                   â”‚
â”‚                                                                             â”‚
â”‚  STEP 3: START STREAMING SERVICES                                          â”‚
â”‚  â”œâ”€â”€ Spark Master + 2 Workers                                              â”‚
â”‚  â”œâ”€â”€ MLflow tracking server                                                â”‚
â”‚  â”œâ”€â”€ Airflow webserver + scheduler                                         â”‚
â”‚  â””â”€â”€ FastAPI application                                                   â”‚
â”‚                                                                             â”‚
â”‚  STEP 4: SEED INITIAL DATA                                                 â”‚
â”‚  â”œâ”€â”€ 5 test assets created in PostgreSQL                                   â”‚
â”‚  â””â”€â”€ 15 sensors registered                                                 â”‚
â”‚                                                                             â”‚
â”‚  STEP 5: INGEST TO KAFKA                                                   â”‚
â”‚  â”œâ”€â”€ Real-time streaming at 100x speed                                     â”‚
â”‚  â”œâ”€â”€ Kafka topic: sensor_readings                                          â”‚
â”‚  â””â”€â”€ Duration: ~60 seconds (simulated)                                     â”‚
â”‚                                                                             â”‚
â”‚  STEP 6: VERIFY PIPELINE                                                   â”‚
â”‚  â”œâ”€â”€ Spark processes streams â†’ MongoDB                                     â”‚
â”‚  â”œâ”€â”€ Raw readings: MongoDB sensor_readings collection                      â”‚
â”‚  â””â”€â”€ Aggregations: 5min, 1hour windows computed                            â”‚
â”‚                                                                             â”‚
â”‚  STEP 7: API TESTS                                                         â”‚
â”‚  â”œâ”€â”€ Health checks: âœ… PASS                                                â”‚
â”‚  â”œâ”€â”€ Authentication: âœ… PASS                                               â”‚
â”‚  â”œâ”€â”€ Asset CRUD: âœ… PASS                                                   â”‚
â”‚  â”œâ”€â”€ Alert rules: âœ… PASS                                                  â”‚
â”‚  â””â”€â”€ Dashboard reports: âœ… PASS                                            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ Expected Data Volumes

| Metric | Expected Value |
|--------|---------------|
| **Raw Records** | 20,631 (from CMAPSS) |
| **Converted Readings** | ~82,524 (4 sensors Ã— 20,631) |
| **Assets Created** | 5 (seed) + 100 (CMAPSS engines) |
| **Sensors** | 15 (seed) + 400 (CMAPSS) |
| **MongoDB Documents** | 82,500+ sensor readings |
| **Aggregations (5min)** | ~2,750 windows |
| **Aggregations (1hour)** | ~230 windows |

## âœ… Expected API Test Results

### Health Checks
```bash
GET /health
â†’ {"status": "healthy", "version": "1.0.0"}

GET /health/ready
â†’ {"status": "ready"}
```

### Authentication
```bash
POST /auth/token
â†’ {
  "access_token": "eyJhbGc...",
  "token_type": "bearer",
  "tenant_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_role": "admin"
}
```

### Assets
```bash
GET /assets/{tenant_id}
â†’ {
  "total": 105,
  "items": [...],
  "page": 1,
  "page_size": 20
}
```

### Dashboard Report
```bash
GET /reports/{tenant_id}/dashboard
â†’ {
  "total_assets": 105,
  "assets_by_status": {"operational": 105},
  "total_open_alerts": 0,
  "fleet_health_score": 75.5,
  "health_distribution": {
    "healthy": 80,
    "at_risk": 20,
    "critical": 5
  }
}
```

## ğŸ¯ Key Sensor Readings (CMAPSS)

| Sensor | Type | Range | Unit |
|--------|------|-------|------|
| T50 | Temperature | 1,400-1,600 | Â°C |
| P30 | Pressure | 500-600 | - |
| Nf | Fan Speed | 2,300-2,400 | RPM |
| Nc | Core Speed | 9,000-9,200 | RPM |

## ğŸ“Š Data Quality Indicators

### âœ… Success Criteria

1. **Data Ingestion**
   - [ ] Kafka topic `sensor_readings` created
   - [ ] 82,500+ messages in Kafka
   - [ ] MongoDB has `sensor_readings` collection
   - [ ] 82,500+ documents in MongoDB

2. **Stream Processing**
   - [ ] Spark streaming job active
   - [ ] 5-minute aggregations in MongoDB
   - [ ] 1-hour aggregations in MongoDB
   - [ ] No failed batches

3. **API Functionality**
   - [ ] Health endpoint responds
   - [ ] Authentication returns JWT
   - [ ] Assets API returns 105 assets
   - [ ] Dashboard report generated
   - [ ] Predictions return health scores

4. **Database State**
   - [ ] PostgreSQL: 105+ assets
   - [ ] PostgreSQL: 415+ sensors
   - [ ] MongoDB: 82,500+ readings
   - [ ] MongoDB: aggregations computed

## ğŸ” Verification Commands

After running the pipeline, verify with:

```bash
# 1. Check all services
docker-compose ps

# 2. Check Kafka topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# 3. Check MongoDB document count
docker-compose exec mongodb mongosh foresight --eval "db.sensor_readings.estimatedDocumentCount()"

# 4. Check PostgreSQL asset count
docker-compose exec postgres psql -U foresight -c "SELECT COUNT(*) FROM assets;"

# 5. Test API
curl http://localhost:8000/health

# 6. Get token and test authenticated endpoint
TOKEN=$(curl -s -X POST http://localhost:8000/auth/token \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@assetpulse.local","password":"admin123"}' | jq -r '.access_token')

curl http://localhost:8000/assets/550e8400-e29b-41d4-a716-446655440000 \
  -H "Authorization: Bearer $TOKEN" | jq '.total'
```

## âš ï¸ Common Issues & Fixes

### Issue: Kafka connection refused
```bash
# Fix: Wait longer for Kafka to start
sleep 60

# Or restart Kafka
docker-compose restart kafka
```

### Issue: MongoDB not showing documents
```bash
# Fix: Check Spark streaming is running
docker-compose logs spark-master | tail -20

# Check topic exists
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic sensor_readings
```

### Issue: API returns 500
```bash
# Fix: Check API logs
docker-compose logs api | tail -50

# Restart API
docker-compose restart api
```

## ğŸ“ˆ Performance Expectations

| Operation | Expected Time |
|-----------|--------------|
| Services startup | 30-60 seconds |
| CMAPSS conversion | 5-10 seconds |
| Data ingestion (100x) | 60-120 seconds |
| Stream processing | Real-time |
| API response | <100ms |
| Dashboard query | <500ms |

## ğŸ‰ Success Indicators

You'll know the test was successful when:

1. âœ… All Docker containers show `Up` status
2. âœ… `engine_data.csv` is created (~5-10MB)
3. âœ… MongoDB shows 82,500+ documents
4. âœ… API health check returns `healthy`
5. âœ… API tests show all PASS
6. âœ… Dashboard shows 105+ assets
7. âœ… Spark UI shows completed batches

---

**Ready to run?** Start Docker Desktop, then run:
```bash
./scripts/full_test_pipeline.sh
```
